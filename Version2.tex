\documentclass[11pt]{pnas-new}
% \documentclass[10pt]{article}
\templatetype{pnasresearcharticle} % Choose template 
% {pnasresearcharticle} = Template for a two-column research article
% {pnasmathematics} %= Template for a one-column mathematics article
% {pnasinvited} %= Template for a PNAS invited submission

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{xcolor,ulem}
\usepackage{mdframed}
\usepackage{wrapfig}
\usepackage{multicol}
\setlength{\columnsep}{1cm}
\usepackage{graphicx}
\usepackage{adjustbox}
\usepackage{lipsum}
\newlength{\strutheight}
\usepackage{soul} % for strike-through (\st)



\author[1]{Yoav Freund}
\author[2]{Hau-Tieng Wu}
\affil[1]{UCSD, Computer Science, San Diego, 92093, United States}
\affil[2]{Duke, Mathematics and Statistical Science, Durham, 27708, USA}

\title{You should prefer a digital Doctor that can say\\ "I don't know"}

\input{macros}

\begin{abstract}

  The meteoric rise of AI in general and Deep Learning in particular
  is generating great excitement throughout academia and commerce, and
  in particular in medicine\cite{topol2019deep,
    wachter2015digital}. With some some high-profile claims~\cite{}
  that AI will soon replace humans in many medical specialties.

  In this position paper we present an alternative view. We contrast
  {\em Artificial Intelligence} with {\em Intelligence Augmentation}
  and argue that the second is more likely to benefit the patient than
  the first. We provide evidence to this argument and present a vision
  in which easier decisions are delegated to computers, while the more
  difficult ones are handled by humans.

\end{abstract}

\begin{document}
\settoheight{\strutheight}{\strut}

 
\maketitle

%\thispagestyle{firststyle}

The meteoric rise of AI and Deep learning raises the possibility that
doctors will be replaced computers~\cite{Mukherjee2017}. Geoff Hinton,
a famous deep learning researcher said in 2017: ``It's just completely
obvious that in ten years deep learning is going to do better than
Radiologists ... They should stop training radiologists now''.

The predictions of Sebastian
Thrun~\cite{Mukherjee2017,esteva2017dermatologist}, another leader in
machine learning, are less disruptive: ``... deep learning devices
will not replace dermatologists and radiologists. They will {\em
  augment} professionals, offering the expertise and assistance''. In
this article we argue for Thrun's prediction and explain why
augmentation, rather than replacement, is the approach more likely to
prevail.

\input{AIIABox} The question of whether dermatologists will be
replaced by computers or be empowered by computers is but a recent
incarnation of a debate between AI (Artificial Intelligence) and IA
(Intelligence amplification) which has a long history (see inset). To
distinguish between AI and IA we use the terms ``AI agent'' vs. ``IA
sidekick''. This terminology contrasts {\em agents}, which are endowed
with {\em agency} and can take {\em actions} that effect the patient's
health, with {\em sidekicks} which can provide advice and suggestions,
but who are not allowed to take action.

Replacing dermatologists with AI agents can bring cost savings,
but is likely to lead to inferior care. One of the reasons is that it
is hard for AI to make a human connection with the patient and thereby
take into consideration personal, social, financial and mental factors.

On the other hand, IA powered sidekicks IA can help the medical staff
detect and diagnose medical problems quickly, efficiently,
accurately. This can lead to cost savings, especially for homebound
patients suffering from chronic diseases.

Central to our approach is a quantification of {\em prediction
  confidence}. Such quantification is needed to avoid premature
diagnostic conclusions, and to decide which additional tests or
consultations might be needed. Consider a doctor that is asked asked
to diagnose a patient with complex or conflicting symptoms. A careful
doctor will admit their uncertainty and perform additional tests or
ask a specialist. A less careful, overly self confident doctor is
likely give an incorrect diagnosis and choose an ineffective or even damaging
treatment plan.

An AI agent, trained to be better than the human doctor, might end up
behaving like an overly confident doctor. An IA sidekick, aware of
it's own limitations, will give advice only when the evidence is
strong and otherwise say ``I don't know''.

In the following sections we explore these ideas in more detail. We
start with a critique of one of the papers that claims that AI agents
can outpeform human diagnosticians.

\section{Supervised Learning and the Ground Truth}
\label{sec:ground-truth}

Deep learning is a special case of {\em supervised learning} (see
inset), sometimes called {\em input-output}
learning~\cite{ng2016artificial,topol2019deep}.
\input{Supervised}
The data for supervised learning consists of a large collection
(input,output) pairs. For medical diagnosis, the inputs is medical
information for the patient (Heart rate, blood tests, X-ray images
etc.) and the output is the diagnosis. This output is considered the
``ground-truth'' and is assumed to represent the undisputed truth.

Here lies the the first difficulty with applying supervised learning
to medical diagnosis. In most real-world scenarios the diagnosis
does is not an objectively measurable fact, rather, it
represents the conclusion drawn by a fallible human diagnostician. We  will
return to this issue in the next section.

The other important assumption made in supervised learning is that the
generated classifier is tested using the same distribution of examples
as that of the training set.

We now consider a study in deep neural networks which claims to show
that DNNs can perform diagnostics as well as, or better, than human diagnosticians. 
\input{SkinCancer}
In a highly cited paper in the journal
Science~\cite{esteva2017dermatologist} provides evidence supporting
the claim that computers can diagnose skin cancer as well or better than board
certified dermatologists.

A fundamental problem with the experiment is in the way the data was
collected. The data used in the experiment was {\em retrospective},
i.e. it was collected from the records of past patients for which both
a skin image and a biopsy were available. Normally, patients get
biopsied only if the dermatologist thinks there is a significant
chance of {\bf malignancy}. As a result, a retrospective study that is
based on patients for whom a biopsy was taken is likely to
over-represent malignant patients and therefor be biased. If an image-based classifier
is trained on the biased data, its performance on unbiased test data
is likely to be worse. Specifically, when the classifier is applied to skin
images of undiagnosed patients it is likely to over-diagnose them as
malignant. The practical implication would be that more patients than
necessary will be biopsied.

As we elaborate on in the next section, in medical diagnostics the
ground truth is usually not available, all that we have to go on are
the opinions of human diagnosticians.

\section{Uncertainty in medicine}

For the most part, it is hard to associate ground truth with medical
diagnostics. This is evident studies of {\em inter-rater agreement} (see
inset). In studies of this kind multiple doctors produce diagnostics
based identical medical information without communicating with each other. \input{Arrhythmia}

\input{InterRaterAgreement}

In addition, diagnosis is not an input-output mapping. Rather, it
is an iterative process which reduces uncertainty over time. To
illustrate this, consider the diagnostics of a patient that is treated
in an out-patient clinique..  When a patient arrives at a clinique for
the first time, all diagnostics are possible. After a physical exam
and an interview with a doctor, , many possibilities are
eliminated. In {\em simple} cases, this is enough for the doctor to
confidently choose a treatment. In more complex cases, the doctor
might ask for multiple tests and visits, refer the patient to a
specialist, consult colleagues, journals and books etc. To choose a
treatment plan, the set of possible diagnostics has to be reduced
however, it does not have to be reduced to a {\em single} diagnostics,
as multiple diagnostics might share a treatment plan.

In order to apply a supervised learning method, such as  DNN, to the
diagnostic problem, we need to define a ground-truth label for each
patient. But that is easier said than done. As the final output of the
diagnostic process is a treatment plan, we would like to know what is
the best treatment plan. Unfortunately, we can only use a single
treatment plan to treat the patient, so the most that we might be able
to infer is whether the chosen treatment was effective.  Even if the
patient improved, the cause might have been unrelated to the
treatment. It might be due to a change in diet or reduction in stress.
Moreover, in most cases, there are few or none followup visits and as
a result there is no data as to whether the patient has a lasting
improvement in health.
\input{SignalQuality}


\iffalse
It is certainly expected that physicians can achieve a reliable
decision making, probably with sufficient clinical information
\cite{mehta2011agreement} or if only the major information is needed
\cite{atiya2003interobserver}. However, in many cases, the quality of
decision making might be jeopardized due to various reasons, among
which the uncertainty in medicine is non-negligible.
\yoav{I find the previous paragraph unclear and confusing, We should
  talk about it}
\fi

%Medical uncertainty as manifest by low inter-rater agreement consequence,
%can be found in many clinical problems
There are many causes for uncertainty in medical diagnosis. We briefly
describe four categories of problems: {\em signal quality}, {\em
  Patient Monitors} the {\em knowledge gap} and the limitations of {\em
  diagnostic protocols}.


By {\em Signal Quality} we refer to the quality of the raw data
collected for medical diagnosis. Some diagnostic measures, such
as heart rate, blood pressure and temperature can be measured reliably
and accurately. On the other hand, modern
devices such as EKG, EEG, camera images, X-ray, ultra-sound and MRI
produce vast and highly variable data. The quality of this data
depends on may factors among them, the quality of the instruments, the
consistency of the human operator, the build of the patient etc.

Signal quality enhancement is already an important part of imaging
devices such as X-ray and MRI. Methods such as compressed
sensing~\cite{} are used to reconstruct 3d images from a large number
of noisy scans.

\input{AlarmFatigue}
One situation where signal quality and signal variability is
particularly problematic are Patient Monitors. The purpose of these
devices is to continuously monitor patients vital signs and alert the
medical staff if a dangerous situation is detected. Unfortunately, the
false alarm rate of these devices is often high. This results in a
phenomenon called ``alarm fatigue'' where the medical staff ignores
the generated alarms, rendering them useless.

Signal quality and alarm fatigue can be thought of as ``bottom up''
causes of uncertainty. The uncertainty originates in the medical
devices and moves up to the medical staff.

Other types of uncertainty are ``top down'' in that they originates in medical research percolates down to the medical staff.q We briefly
describe two types of top-down uncertainty: knowledge gaps and the
limitation of medical protocols.

{\em ``Knowledge gap''} corresponds to limitations of scientific medical
knowledge. This is not the limitation of a particular doctor, rather,
it reflects the limitations of knowledge that correspond to successful
medical trials.
\input{KnowledgeGap}

Even when medical knowledge exists, an individual doctor might now
know it. The dissemination of medical knowledge starts in medical
school and continues throughout the medical staff career. In addition,
{\em medical protocols} are used to ensure uniformity and
consistency of treatment between hospitals, doctors and nurses. While
protocols are an important dissemination tool, they have some limitations, 
as described in the inset.
~\\

\section{Uncertainty in machine learning}

We described some of the many causes of uncertainty in medical
diagnosis. One might conclude that the automation of diagnosis in
diseases with high rates of inter-rater disagreement is
impossibe. However, this is not necessarily the case. There are types
of diagnostics for which the typical case is {\em simple}, and only a
small fraction of the cases are {\em complex}.  We use the term
``simple'' to mean that {\em most doctors are likely to give the same
  diagnosis}.  In other words, these are the cases on which
inter-rater disagreement is low. ``Complex'' cases are those where
doctors tend to either say "I don't know" or disagree with each other.
{\em Our proposal is that to allow IA to output ``I don't know'' on
  the complex cases, and, in exchange, require higher levels of
  accuracy and reliability when the IA makes a prediction.}

Increasing confidence in the diagnosis by consulting more than one
doctor and seeking agreement is common sense. Similar ideas have been
used in machine learning algorithms such as Bagging, Random Forests, and
Boosting\cite{}. These so-called ``ensemble'' algorithms combine the outputs
of different ``base'' learning algorithm using a majority vote.

Here, we refine the idea of taking a majority vote. We conform with
the majority vote when the majority vote is clearly tilted towards one
of the possible outcomes (labels, diagnoses). When two or more
outcomes get close to the maximal number of votes, the system outputs
the set of outcomes. This means: I predict that it is one of these
outcomes, but I don't know which one. Similar notions of confidence
have been suggested in~\cite{li2011knows}.

%\newpage
\section{Augmenting medicine}

Unlike AI where the goal is to immitate and ultimately replace the
doctor, the goal for IA is to provide a diagnostic tool that can help
the doctor. Importantly, the responsibility for the well-being of the
patient stays squarely with the doctor. Whether the IA makes a
prediction or outputs ``I don't know'', the final diagnosis and the
treatment plan is the responsibility of the human doctor.

The utility of an IA sidekick to doctor depends on many factors. Among
them the severity of the patient's problems, the patient to doctor
ratio, whether advice from specialists is needed and available, the
experience and self confidence of the doctor etc. This utility is
likely to be high for a lone general practitioner treating a patient
in a rural area with heart problems. It is less likely to be of direct
use in an intensive care unit of a large urban hospital where doctors
with a wide array of specializations are available.

Price et al have studied the ethical, legal and regulatory
aspects of using AI in medicine.\cite{price2014black,ford2016privacy, ford2017regulating}
\input{ProtocolLimitations}

The consequence of an case being labeling as ``Complex'' by an IA, is
that the case is passed to a human doctor for making a decision. The
doctor can proceed in a variety of ways. She can use her superior
ability to make a diagnosis, she can order more tests, consult other
doctors, make a treatment plan based on partial knowledge etc.

So far, we have discussed components: Machine learning IA, medical
uncertainty and ways of controlling and reducing it. We now turn our
sights to system and organizational issues, and try to answer the
question ``why would doctors, nurses and hospitals adapt such technology''.

We quote from Robert Rechter's book "The digital doctor"~\cite{wachter2015digital}:
\begin{quote}
  Harvard psychiatrist and leadership guru Ronald Heifetz has
  described two types of problems: technical and adaptive. Technical
  problems can be solved with new tools, new practices, and
  conventional leadership. Baking a cake is a technical problem:
  follow the recipe and the results are likely to be fine. Heifetz
  contrasts technical problems with adaptive ones: problems that
  require people themselves to change. In adaptive problems, he
  explains, the people are both the problem and the
  solution. Leadership, he once said, requires mobilizing and engaging
  people around a problem “rather than trying to anesthetize them so
  you can go off and solve it on your own.”
\end{quote}

Rechter continues to say that the digitization of medicine "the Mother
of All Adaptive Problems". In other words, for AI to be widely
adapted, doctors and nurses ("medic" in the following) need to
positively engage in its adaptation. Declaring that AI will soon
replace medics, positions AI in an adversarial stance towards medics
and is likely to make them more resistant to the adoption of AI
technology~\cite{topol2019deep}.

Moreover, as argued above, claims that AI can perform diagnosis more
accurately than most medical professionals are overblown. On the other
hand, if we allow the IA system to output ``I don't know'' on
the hard cases, we can achieve high accuracy on the easier cases. 

\section{How to augment doctors}
Medical diagnosis is often uncertain or inconclusive. On the other
hand, a doctor responsible for a patient's health has to make
decisions in spite of this uncertainty. If the uncertainty presents a
sufficiently small risk, the doctor can choose a treatment. Otherwise
the doctor might consult other doctors, a medical journal or a book. 

To better understand the process and the possible place of AI in it,
we turn to the Kahaneman's~\cite{kahneman2011thinking} ``Thinking Fast Thinking Slow'' and
to Vordermark book on medical decision
making~\cite{vordermark2019introduction}.

Medical diagnosis can be divided into two main types: {\em
  recognition} and {\em elimination}. Recognition is a fast mental
process that is partially unconscious where the one correct diagnosis presents itself in the doctors mind.  Sometimes the doctor is not able to explain their recognition in words, which hinders discussion and documentation.  As recognition 
typically points to a single diagnosis, there is a danger that the
recognized diagnosis will hide other possible diagnoses.
Elimination, on the other hand, is a slow deliberate process  which starts with all possible diagnoses and gradually eliminates
unlikely ones based on patient history, examination and test
results. As Elimination is deliberative, it is easier to discuss and
document it.

In both recognition and elimination, past experience plays an important role. This experience is based on medical practice as well as knowledge learned from lectures or books. 

IA can aid the doctor both in Recognition and in Elimination. On the Recognition side, an IA can sift through massive data and point the diagnostician to suspicious areas.

On the Elimination side, an IA system could help carefully and systematically
eliminate diagnoses. This can help the doctor stay aware of possibilities that are not obvious, for differential diagnosis.


\iffalse
To make a decision based
on elimination, slow thinking with focused attention is critical
\cite{michel2020thinking}. 

An intelligent system could be extremely helpful for this
purpose. An intelligent system could help carefully and slowly
eliminate possible choices, and if it end up in a gray zone with
multiple possibilities, it says IDK. This would dramatically help
physicians daily practice.

{\bf Sources of uncertainty in medical diagnosis.}
\begin{itemize}
  \item{\bf The diagnostic process of elimination}
  \item{\bf Data Quality, Calibration, resolution} Discuss issue as placement of sensors, .
  \end{itemize}

 {\bf Hiding Uncertainty}
  \begin{itemize}
    \item {\bf Psychological reasons} Both doctor and patient prefer
      the projection of certitude.
    \item {\bf Protocols} --done
    \item {\bf diagnostic devices} Secrecy of the internal code limits
      the trustworthiness of the alarms.--done
    \item{\bf Alarm Fatigue}--done
  \end{itemize}
%{\bf Psychological reasons} Both doctor and patient prefer


How to quantify IDK? We should discuss how to quantify the confidence, or certainty, a physician has when making a decision. 
\ML{Certainty and conditional probability}{
This certainty is very different from the the conditional probability of the disease given the diagnostic. The first is
      akin to saying: 95\% of the dermatologists would give the same
      diagnostics. The second defines the probability that, if we had
      access to ground truth, then 95\% of the patients that receive
      this diagnostics have the corresponding condition.
}  
\fi
Clearly, experience leads to confidence. With more experience aggregated, diagnostic options that contradict the accumulated
  experience are eliminated, and hence more problems that need to be handled by the elimination process can be handled by the recognition process. However, facing our complicated human body, it is almost not possible for any single physician to aggregate all necessary experience to be confident about anything, so IDK is still an option. A practical and simple way to increase diagnostic certainty is to solicit the experience of a diverse group of doctors via discussion. If there is a clear majority for one diagnostic outcome,
      then the overall confidence in that diagnostics is high. While this voting procedure might guarantee the optimal outcome, it eliminates the uncertainty during the whole procedure. With this certain procedure, even if the outcome is negative, it can be traced back and accumulate evidence and experience. 

\section{How to augment medical institutions}

  Computer {\color{blue}has been} an integral part of medical practice {\color{blue}for decades}. From
  {\color{blue}electronic} medical records (EMR) to medical instrumentation to billing,
  hospitals and cliniques cannot function without computers. By some
  measures computers can already make better diagnosis than human
  doctors. The question is not {\em whether} computer diagnostics will
  become part of medical practice, the question is {\em how}.

  Some claim that human doctors and nurses are heading to extinction,
  following the fate of manufacturing jobs and bank cashiers.  Our
  prediction is that computers will change the nature of medical
  work. Our prediction is that the adaptation of IA will increase,
  rather than decrease, the number of healthcare workers. especially
  in the care of chronic disease and aging \st{and exploring the
    nature of our complicated human body}.

  Consider an established clinique or hospital. While every day brings
  in new cases, it is likely that for many of these cases the
  diagnosis is ``easy'', i.e. the same diagnosis would be given by
  most doctors. If the IA sidekick identify a significant fraction of
  the patients that are clearly sick or the patients that are clearly
  ok, then it can help the staff prioratize treatment. For example,
  patients identified in critical condition can get to see a senior
  doctor faster, while patients that are confidently identified as
  healthy are directed to a junior doctor or to a nurse practitioner.

\yoav{Until here}
  
  
  We believe computers {\em can} perform accurate diagnosis for cases where
  different doctors are likely to agree. In other cases {\color{blue}that are in the}
  diagnostic gray area, the computer will output ``I don't know'' and
  transfer the responsibility to the doctor. In most cases, the doctor
  cannot say ``I don't know'' because she is responsible for the
  patients health. On the other hand, resolving the diagnostic
  question is not her only choice. She can consult another doctor or
  the literature, ask for additional tests, or decide on a treatment
  based on available information. Deciding between these options requires much
  more than diagnostic information. It involves understanding the
  patient's emotional, mental and financial state, the patient's
  support system, the strengths and weaknesses of the hospital in
  which this is taking place etc. {\color{blue}Such exploration and results will be fed back to the system to reduce the gray area, which is similar to training an intern doctor in the hospital.}

  Over time, computers will be able to take into consideration more
  and more of this complex information. However, for the foreseeable
  future, it is unlikely that computers will be given the
  responsibility to make medical {\em decisions}. Computers
  will take on much of the diagnostics and alarm tasks, improving the
  accuracy and timeliness of the doctors actions. Computers will
  output IDK in gray areas and will leave the decision making to the
  human doctor. Giving the computer the authority to make decisions
  currently done by human doctors will {\color{blue}not only} deprive the patient the human
  attention of the doctor{\color{blue}, but also put patients in risk}.

  Some of the digitization of the medicine has come between patients
  and doctors. {\color{blue}A common impression from the learning perspective is that physicians need to record more activities and hence reduce the amount of time on interacting with patients. However, we} %\sout{The need to record all activities into the EMR system requires doctors to spend more time at the keyboard, reducing the amount of time of physical examination an discussion}. \hautieng{I guess I know what you want to say, but to be safe, I'll do the edit here after we chat.} 
  believe that {\color{blue}a properly designed } IA {\color{blue}that knows IDK} can
  move medicine in the opposite direction, letting the computer make
  the common noncontroversial diagnostics and giving the patient more
  time to interact with the patient.

%\begin{figure}[h]
%\begin{center}
%\includegraphics[trim=0 100 0 200,clip,width=7in]{figures/RedYellowGreen2.pdf}
%\caption{An illustration of how an alarm system works as a radar system. The red and green pentagons indicate the danger and safe region of five indices. A set of indices inside the green pentagon is safe (shown as a green light). If any index is outside the red pentagon, the patient is surely in danger (shown as a red light). However, if any index is outside the green pentagon but inside the red pentagon, the patient is in a ``gray zone'', or marginal situation, the system might not be able to decide the situation, and will report IDK (shown as a yellow light).\label{Figure IDK light}}
%\end{center}
%\end{figure}

  For IA technology to be widely adopted, the nurses and doctors that
  use them should experience an improvement in their practice {\color{blue}with the IA system. One example of such system is}
  that the display of the diagnostics computer uses a three color code
  to identify {\color{blue}the pre-defined status. In this system,} green indicates a confident
  negative diagnostic, red corresponds to a confident positive
  diagnosis, and yellow corresponds to IDK, meaning that the
  computer cannot confirm or reject the diagnostic outcome. {\color{blue}%See Figure \ref{Figure IDK light} for an illustration of such a system with a radar display. The thresholds that define these three ranges depend on our knowledge, and the data uncertainty and protocol issues should be taken into account. 
  With the IA system with IDK, healthcare providers could focus their time on patients overall situation, communication for life plan, or other interactions, and intervene the medical diagnostics when the IA system says IDK.}

%  The thresholds which define the three ranges .... \hautieng{discuss.}


  
  We finish this section with a few application areas which seem ready
  for applications of IA.
  
\begin{itemize}
\item{\bf Computer aided diagnostics for large-scale data}\\
  Medical imaging devices such at digital X-ray, CT, EMR and scanning
  microscope generate many gigabytes of data for each
  patient. Radiologists and pathologists spend their days analyzing
  these images to diagnose the patient. The large size and high
  resolution of the images on the one hand, and the time limitation on
  the analyst on the other imply that the analyst has to quickly
  narrow down the suspicious region, increase the chance of missing
  dangerous abnormalities.

  IA can help the pathologist by suggesting locations in the high
  resolution image that might contain cancer nodules~\cite{}.

  directing her attention to the
  parts of the image that are 

\item{\bf Adaptive Patient monitors}

{\color{blue} By further accumulating knowledge, reducing data uncertainty, and improving protocol, it is expected that the gray zone a well developed IA system has is small, and the alarm fatigue issue is alleviated since it only makes an alarm when it runs into IDK. There are many other aspects such an IA system equipped with IDK could help. Since the system knows IDK, it knows what is affirmative. When a medical decision made by a physician falls in the affirmative area, the IA system could help doubly confirm if the decision has any risk not considered by the physician. Such alarm, when sufficiently accurate, could help improve patient risk and healthcare quality. Eventually, this IA system could be evolved into a second opinion provider to healthcare providers. 
}

\item {\bf Dissemination of expertise}

Computers, trained by experts, can help novices. {\color{blue}A well-trained IA system equipped with IDK can provide confirmed answers to inexperienced physicians, and} serve a function
similar to score-cards{\color{blue}. Moreover, it can be applied to areas with scarce health resource. The system can provide local healthcare providers knowledge they do not know, and be connected back to physicians with richer medical knowledge when it runs into IDK.
On the high level, eventually, we can view an IA system with IDK as a medical specialist full of knowledge and do not make mistake when it knows the answer. When it encounters IDK, it will not hide it. The feedback from experienced physicians, or newly developed knowledge, could be input to decrease the gray areas, and reduce the chance of encountering IDK. Such system in the beginning behaves like an intern doctor, and teaching it is like}
teaching young diagnostics. {\color{blue}Due to the brain capacity and physical limitation, it is impossible for a single physician to know everything in every field, and it is possible that even a very experienced physician could make a mistake. Such a well trained IA system can eventually serve as a reliable second opinion provider to experienced physicians.}
\end{itemize}

%\bibliographystyle{alpha} 
\bibliography{medbib}

\end{document}