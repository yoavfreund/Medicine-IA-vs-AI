\documentclass[11pt]{pnas-new}
% \documentclass[10pt]{article}
\templatetype{pnasresearcharticle} % Choose template 
% {pnasresearcharticle} = Template for a two-column research article
% {pnasmathematics} %= Template for a one-column mathematics article
% {pnasinvited} %= Template for a PNAS invited submission

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{xcolor}
\usepackage{mdframed}
\usepackage{wrapfig}
\usepackage{multicol}
\setlength{\columnsep}{1cm}
\usepackage{graphicx}

\author[1]{Yoav Freund}
\author[2]{Hau-Tieng Wu}
\affil[1]{UCSD, department, city, postcode, country}
\affil[2]{Duke, department, city, postcode, country}

\title{Sometimes the digital Doctor should admit\\ "I don't know"}

\input{macros}

\begin{abstract}

  The meteoric rise of AI in general and Deep Learning in particular
  is generating great excitement throughout academia and commerce, and
  in particular in medicine\cite{topol2019deep,
    wachter2015digital}. With some some high-profile claims~\cite{}
  that AI will soon replace humans in many medical specialties.

  In this position paper we present an alternative view. We contrast
  {\em Artificial Intelligence} with {\em Intelligence Augmentation}
  and argue that the second is more likely to benefit the patient than
  the first. We provide evidence to this argument and present a vision
  in which easier decisions are delegated to computers, while the more
  difficult ones are handled by humans.

\end{abstract}

\begin{document}

\maketitle

%\thispagestyle{firststyle}

Digital technology is causing a sea-change in all parts of the medical
profession. In particular the meteoric rise of AI in general and deep
learning in particular raises the possibility that doctors will be
replaced computers~\cite{Mukherjee2017}. The father of deep learning,
Geoff Hinton, said in 2017: "It's just completely obvious that that in
ten years deep learning is going to do better than Radiologists
... They should stop training radiologists now".
\Org{Artificial Intelligence and Intelligence Augmentation}{
Using computers to augment human intelligence rather replace it is
both tantalizing and mundane. On the heady side, consider
cyborgs whose anatomy is part human, part artificial and can with
equal ease solve complex equations or write poetry. On the mundane
side, think of smartphones that are quickly becoming an inseparable
part of our person.
 
The idea of using computers to augment or amplify human intelligence
has a very long history. The acronyms AI (Artificial intelligence) and
IA (Intelligence Amplification or Intelligence Augmentation) have both
become popular in the early
1960's\cite{ashby1957introduction,engelbart1962augmenting}. These
days, the acronym AI is popular, while the acronym IA is not. However,
Sebastian Thrun's statement indicates that the idea of Intelligence
augmentation is still on people's mind.}

Other deep learning researchers provide a more nuanced
perspective. Sebastian
Thrun~\cite{Mukherjee2017,esteva2017dermatologist} argues that
"... deep learning devices will not replace dermatologists and
radiologists. They will {\em augment} professionals, offering the
expertise and assistance". {\bf What would IA look like when applied to medicine?} that is the
question we aim to answer here.  We argue that an important ingredient
of the answer is to introduce to AI agents a level of
humility. Specifically, to design classifiers, such as DNNs, to say "I
don't know".

\section*{Labels, ground truth and testing}
In their famous work, Esteva et al. set out to show that a classifier
trained by machine learning can performs as well as or better than
expert dermatologists.  In this application of supervised learning
each example consists of an input image of a skin patch and an output
label that is ``benign'' or ``melignant''
\ML{Supervised Learning and ground truth}{Roughly
  speaking, machine learning (ML) can be divided into {\em
    unsupervised} learning and {\em supervised} learning. In both, the
  task of the learning algorith is transform a set of {\em examples}
  into a {\em model}. In unsupervised learning the examples are
  undifferentiated raw measurements. In {\em supervised} learning,
  which is the focus of this article, each example consists of an {\em
    input} and a {\em label}. Typically, the labels are provided by a
  human expert. These labels define the {\em ground truth} and the
  goal of the learning algorithm is to make predictions that diverge
  as little as possible from the ground truth.}

As they wanted to compare the system to human dermatologists they
needed a better ground truth than that provided by the dermatologists.
To that end they used the diagnosis of a biopsy as ground truth. It is
arguable that this label is more accurate than the one given by the
dermatologist, even though it depends on the human judgement of the pathologist.
\ML{Skin cancer diagnosis using Deep Neural Networks}{One of the
  papers that provided evidence that deep neural networks might be
  able to outperform humans is the work of Esteva et
  al~\cite{esteva2017dermatologist}. They trained a Deep neural
  network to classify images of skin into three categories: benign,
  malignant and non-cancerous. The network was then tested, along with
  twenty five dermatologists on images which were labeled by a
  pathologist analysis of the biopsy. The neural network outperformed
  the human dermatologist. This is, without a doubt, an impressive
  finding. However, it is based on a retrospective analysis, in other
  words, an analysis of historical data. To predict the performance of
  the DNN when used in a dermatology practice we need to how a
  dermatologist, or any other diagnosticians, arrives at their final
  diagnostics.}
However, even if we assume that pathologists labels are more reliable
than dermatology labels, the requirement that each example corresponds
to a biopsy introduces a significant bias. Under normal circumstances, patients get
biopsied only if the dermatologist thinks there is a chance of
{\color{blue}malignancy. Therefore}, the set of biopsied examples is biased towards
{\color{blue}malignancy}. It is likely that using a classifier trained in this way
on an unfiltered stream of patients will increase the number of
patients unnecessarily getting a biopsy.

\section*{Uncertainty in medicine}

Medicine is rife with risk and uncertainty. An incorrect diagnosis or
treatment can cost the patient his life and the doctor her license.

Uncertainty has many causes, we discuss some of those below.
\iffalse
and we elaborate data calibration/validation limitation, protocol limitation, and knowledge gap that are directly related to the intelligent system development. 

It is certainly expected that physicians can achieve a reliable
  decision making, probably with sufficient clinical information
  \cite{mehta2011agreement} or if only the major information is needed
  \cite{atiya2003interobserver}. However, in many cases, the quality
  of decision making might be jeopardized due to various reasons,
  among which the uncertainty in medicine is non-negligible.
\fi  
\Medicine{Uncertainty due to signal Quality}{Medical devices use a variety of bio-sensors that record,
  display and distribute different biometrics, ranging from vital
  signs such as heart rate, oxygen saturation and blood pressure, to
  high-frequency waveforms such as ECG, EEG, respiratory
  signal and arterial blood pressure.
These signals suffer from variety of problems and artifacts, some of which depend on the patient. Reducing these problem often requires a human expert. In some cases such as EEG removal of artifacts is still an open problem~\cite{}.

Patient monitors are bedside devices that monitor patients at risk, freeing the medical staff to attend to the patients that need care at the moment. 
However, Patient monitors suffer from signal quality issues and tend to generate false alarms at a high rate. These cause the medical staff to ignore the
  alarms, rendering them useless. This phenomenon, called {\em alarm fatigue} (or alarm
  overload) is a major problem in hospital care
  \cite{cvach2012monitor,brief2019top}.
}

  \Medicine{Protocol limitation}{
  The American Academy of Sleep
    Medicine (AASM) publishes criteria for manual sleep stage
    and
    sleep apnea annotation from the gold standard sleep study instrument, the polysomnogram (PSG). This annotation is based on manual analysis
    of biosignals recorded from the PSG \cite{Iber2007,berry2012aasm}. The AASM is a protocol that has been extensively applied, with rigorous scientific support, and updated regularly according to latest evidences. 
    %
    A detail sleep profile is critical for sleep quality enhancement, or even medical condition improvement.
    %
    However, it is well known that even with the well established protocol, the inter-rater agreement rate of sleep stage annotation among experienced experts is only about 76\% over normal subjects and about 71\% over subjects with sleep apnea \cite{norman2000interobserver}. Among many reasons, the one that is directly related to the intelligent system development is how the criteria are ``described'' in the protocol. For example, it is described in the protocol that if the delta wave occupies more than 20\% of a given 30-second epoch of the electroencephalogram during sleep, that 30-second epoch is defined to be the N3 stage. 20\% of a given 30-second epoch is 6 seconds. What about if the delta wave occupies 5.99-, or 6.01-seconds? What about if the delta wave sustains for 10 seconds, but it is divided into two consecutive 30-second epochs? When sitting on the ``gray area'' that is inherited from 
  the protocol, sleep experts need to make a
  decision based on their experience or the information
  they have at hand, and this leads to medical uncertainties, and hence the inter-rater, or even intra-rater disagreement.  
  
  
    
  %For example, the inter-rater agreement rate of identifying ventricular premature contractions from a 12 leads electrocardiogram is high among well-trained cardiologists, but it will be lower if only a single lead electrocardiogram is available in the ambulatory environment.

  }

  \ML{Quantification of inter-rater agreement rate}{+Cohen's kappa,
    \yoav{Introduce Hoen kappa. Instead of mathematical definition, I
      would interpret some specific values: the value that
      corressponds to perfect agreement for positive perfect agreement
      for negative, the values that corresond to random-level
      agreement for positive and negative, etc.}}


  \Medicine{Bladder and sphincster diagnosis}{  
  Urodynamic studies provide the best bladder and sphincter functional data for urologists to decide how to treat patients at risk for renal damage \cite{abrams2003describing}.  While it has been extensively studied and applied in clinics, the main issue that plagues this field of urodynamics is the lack of precise definition of a detrusor contraction or overactive contraction \cite{abrams2003describing}.
%  
  The lack of a well defined definition is due to the lack of quantitative study from the pathophysiological perspective, so the definition is still based on ``expert opinion''. For example, usually an overactive contraction represents itself as a ``bump'' in the detrusor pressure signal. However, what is the breath and height of a bump should we call it an overactive contraction? How to distinguish a true overactive contraction from an artifact? While there have been several reference information, like abdominal pressure, that could help us identify artifacts, but it can only explain a small portion of them. 

  Unsurprisingly, this fundamental issue has led to a significant
  inter-rater disagreement
  \cite{venhola2003interobserver,dudley2018interrater}.

    \yoav{What are the cohen-kappa numbers}
  }


  Medical uncertainty as manifest low inter-rater agreement
  consequence, can be found in many clinical problems (see blocks on
  ...)For example, the low agreement might come from the
  ``extrapolation error''; that is, when we apply the developed
  protocol to the population different from the population that we
  collect the evidence for the protocol \cite{brosnan2015modest}.  In
  other situation, the variability among subjects is so big that it
  limits the development of a more quantitative protocol
  \cite{venhola2003interobserver}. In some situations, when the needed
  information is missing, it is challenging to make a differential
  diagnosis \cite{moncada2011reading}.

  A direct consequence of the low inter-rater agreement rate is that the trained intelligent system might be questionable. 
%  
It is clear that such intelligent system is questionable and might raise concerns. Recently, various regulations in this regard have been proposed \cite{price2014black,ford2016privacy}.

\hautieng{should we jump into GDPR?}
\yoav{what is GDPR?}

Now, suppose we are able to eliminate all challenges from data
calibration and validation issues, and we can provide as much
information as possible to train the intelligence system. Even under
this assumption, it is clear that the system still suffers from the
protocol limitation or knowledge gap issues. Can such system be useful
in clinics? To answer this question, we should not forget that
physicians also follow the same protocol and have knowledge
gaps. Depending on the clinical problems, and the experience of
physicians under consideration, the agreement rate varies. Usually,
intern doctors know the least, while a senior attending knows the
most. It is natural that we trust a senior expert more, but it does
not mean that we do not trust a junior intern doctor.

We consider the management of uncertainty from the medical decision making process
point of view\cite{vordermark2019introduction}.
  \Medicine{Inter-Rater agreement}{
  A direct consequence of this low inter-rater agreement is a
  questionable trained ``artificial intelligence''. It is possible
  that we magically obtain a dataset that contains information that is
  sufficient for the decision making, while the information is too
  subtle so that it is not considered in the protocol, and we also
  magically obtain labels from a magical master that can see though
  all the information and provide the correct decision. However, by
  doing a simple math, we shall not count on such a magic and should
  come back to the protocol itself.
}
Following the ``thinking fast, thinking slow'' dualism Kahaneman and
Tversky, it is generally agreed that
two distinct mental processes are involved in choosing a diagnosis.
Recognition is a fast, typically non-verbal, mental process in which
the doctor identifies a pattern in the symptoms and instinctively
makes a diagnosyis. On the other hand, elimination is a slow
deliberative process through which the doctor methodically eliminates
diagnostic possibilities.
 To make a decision based
on elimination, slow thinking with focused attention is critical
\cite{michel2020thinking}. This process is like taking a math
examination, it takes time and effort, and it is exhaustive. In the
every end, depending on the physician experience, he/she might end up
with multiple possibilities. He/she could either guess and proceed, or
say IDK and consult a higher level experts or discuss with other
experts.
\yoav{I like the last paragraph very much, it makes a lot of
  sense. I downloaded the vordermark book. I found a lot of good
  stuff. But I did not find anything about doctors consulting each
  other, majorities, concensus etc. It would be very relevant to find
  information both about how decision are made in today's hospital,
  and how they {\em should} be made to combine the best of fast and
  slow thinking. All of this before saying anything about using ML}

\iffalse % should me moved to uncertainty in ML
An intelligent system could be extremely helpful for this
purpose. An intelligent system could help carefully and slowly
eliminate possible choices, and if it end up in a gray zone with
multiple possibilities, it says IDK. This would dramatically help
physicians daily practice.
\fi

{\bf Sources of uncertainty in medical diagnosis.}
\begin{itemize}
  \item{\bf The diagnostic process of elimination}
  \item{\bf Data Quality, Calibration, resolution} Discuss issue as placement of sensors, .
  \end{itemize}

 {\bf Hiding Uncertainty}
  \begin{itemize}
    \item {\bf Psychological reasons} Both doctor and patient prefer
      the projection of certitude.
    \item {\bf Protocols} --done
    \item {\bf diagnostic devices} Secrecy of the internal code limits
      the trustworthiness of the alarms.--done
    \item{\bf Alarm Fatigue}--done
  \end{itemize}

%{\bf Psychological reasons} Both doctor and patient prefer

How to quantify IDK? We should discuss how to quantify the confidence, or certainty, a physician has when making a decision. 
\ML{Certainty and conditional probability}{
This certainty is very different from the the conditional probability of the disease given the diagnostic. The first is
      akin to saying: 95\% of the dermatologists would give the same
      diagnostics. The second defines the probability that, if we had
      access to ground truth, then 95\% of the patients that receive
      this diagnostics have the corresponding condition.
}  
Clearly, experience leads to confidence. With more experience aggregated, diagnostic options that contradict the accumulated
  experience are eliminated, and hence more problems that need to be handled by the elimination process can be handled by the recognition process. However, facing our complicated human body, it is almost not possible for any single physician to aggregate all necessary experience to be confident about anything, so IDK is still an option. A practical and simple way to increase diagnostic certainty is to solicit the experience of a diverse group of doctors via discussion. If there is a clear majority for one diagnostic outcome,
      then the overall confidence in that diagnostics is high. While this voting procedure might be guarantee the optimal outcome, it eliminates the uncertainly during the whole procedure. With this certain procedure, even if the outcome is negative, it can be traced back and accumulate evidence and experience. 

\section*{Uncertainty in Machine Learning}

One can define ``confidence'' in machine learning. The definition follows a
similar logic to the one used for human diagnosticians in the previous
section. The yardstick by which we measure confidence of predicting a
label is ``how much do alternative labels contradict previous
experience?''.
More formally, we ask how much do we need to change the training data
so that it supports an alternative label.
%\ML{Uncertainty vs. accurracy}{using ROC curves}

\begin{itemize}
  \item Bootstrap samples.
  \item Samples from different hospitals.
  \item Easy and hard cases.
  \end{itemize}

  \section*{Human decisions and Intelligence augmentation}

  Computers are an integral part of medical practice. From
  electronical medical records to medical instrumentation to billing,
  hospitals and cliniques cannot function without computers. By some
  measures computers can already make better diagnosis that human
  doctors. The question is not {\em whether} computer diagnostics will
  become part of medical practice, the question is {\em how}.

  Some claim that human doctors and nurses are heading to extinction,
  following the fate of manufactoring jobs and bank cashiers.  Our prediction is
  that computers will change the nature of medical work, but that it
  will increase, rather than decrease, the number of healthcare
  workers, especially in the care of chronic disease and aging.

  We believe computers {\em can} perform accurate diagnosis for cases where
  different doctors are likely to agree. In other cases which are
  diagnostic gray area the computer will output ``I don't know'' and
  transfer the responsibility to the doctor. In most cases, the doctor
  cannot say ``I don't know'' because she is responsible for the
  patients health. On the other hand, resolving the diagnostic
  question is not her only choice. She can consult another doctor or
  the literature, ask for additional tests, or decide on a treatment
  based on available information. Deciding between these options requires much
  more than diagnostic information. It involves understanding the
  patient's emotional, mental and financial state, the patient's
  support system, the strengths and weaknesses of the hospital in
  which this is taking place etc.

  Over time, computers will be able to take into consideration more
  and more of this complex information. However, for the forseable
  future, it is unlikely that computers will be given the
  responsibility to make medical {\em decisions}. Computers
  will take on much of the diagnostics and alarm tasks, improving the
  accuracy and timeliness of the doctors actions. Computers will
  output IDK in gray areas and will leave the decision making to the
  human doctor. Giving the computer the authority to make decisions
  currently done by human doctors will deprive the patient the human
  attention of the doctor.

  Some of the digitization of the medicine has come between patients
  and doctors. The need to record all activity into EMR system require
  doctors to spend more time at the keyboard, reducing the amount of
  time of physical examination an discussion. We believe that IA can
  move medicine in the opposite direction, letting the computer make
  the common noncontroversial diagnostics and giving the patient more
  time to interact with the patient.

\begin{figure}[h]
\begin{center}
\includegraphics[width=3in]{figures/RedYellowGreen.pdf}
\end{center}
\end{figure}

  For IA technology to be widely adopted, the nurses and doctors that
  use them should experience an improvement in their practice. Suppose
  that the display of the diagnostics computer uses a three color code
  for each . Green indicates a confident
  negative diagnostic, red corresponds to a confident positive
  diagnosis. Finally, yellow corresponds to IDK, meaning that the
  computer cannot confirm or reject the diagnostic outcome.

  The thresholds which define the three ranges .... 


  
  We finish this section with a few application areas which seem ready
  for applications of IA.
  
\begin{itemize}
\item{\bf Computer aided diagnostics for large-scale data}\\
  Medical imaging devices such at digital X-ray, CT, EMR and scanning
  microscope generate many gigabytes of data for each
  patient. Radiologists and pathologists spend their days analyzing
  these images to diagnose the patient. The large size and high
  resolution of the images on the one hand, and the time limitation on
  the analyst on the other imply that the analyst has to quickly
  narrow down the suspicious region, increase the chance of missing
  dangerous abonormalities.

  IA can help the pathologist by suggesting locations in the high
  resolution image that might contain cancer nodules~\cite{}.

  directing her attention to the
  parts of the image that are 

\item{\bf Adaptive Patient montors}
  
\item {\bf Dissemination of expertise}
Computers, trained by experts, can help novices.  Serves a function
similar to score-cards.

Teaching young diagnostics
\end{itemize}

\section*{Summary}

%\bibliographystyle{alpha} 
\bibliography{medbib}

\end{document}