\documentclass[9pt,twocolumn,twoside]{pnas-new}
% \documentclass[10pt]{article}
\templatetype{pnasresearcharticle} % Choose template 
% {pnasresearcharticle} = Template for a two-column research article
% {pnasmathematics} %= Template for a one-column mathematics article
% {pnasinvited} %= Template for a PNAS invited submission

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{xcolor}
\usepackage{mdframed}
%\usepackage{wrapfig}
\usepackage{multicol}
\setlength{\columnsep}{1cm}

\author[1]{Yoav Freund}
\author[2]{Hau-Tieng Wu}
\affil[1]{UCSD, department, city, postcode, country}
\affil[2]{Duke, department, city, postcode, country}

\title{When the digital Doctor should admit\\ "I don't know"}

\input{macros}

\begin{abstract}

  The meteoric rise of AI in general and Deep Learning in particular
  is generating great excitement throughout academia and commerce, and
  in particular in medicine\cite{topol2019deep,
    wachter2015digital}. With some some high-profile claims~\cite{}
  that AI will soon replace humans in many medical specialties.

  In this position paper we present an alternative view. We contrast
  {\em Artificial Intelligence} with {\em Intelligence Augmentation}
  and argue that the second is more likely to benefit the patient than
  the first. We provide evidence to this argument and present a vision
  in which easier decisions are delegated to computers, while the more
  difficult ones are handled by humans.

\end{abstract}

\begin{document}

\maketitle

\thispagestyle{firststyle}

\section*{Introduction}

Digital technology is causing a sea-change in all parts of the medical
profession. In particular the meteoric rise of AI in general and deep
learning in particular raises the possibility that doctors will be
replaced computers~\cite{Mukherjee2017}. The father of deep learning,
Geoff Hinton, said in 2017: "It's just completely obvious that that in
ten years deep learning is going to do better than Radiologists
... They should stop training radiologists now".

Other deep learning researchers provide a more nuanced
perspective. Sebastian
Thrun~\cite{Mukherjee2017,esteva2017dermatologist} argues that
"... deep learning devices will not replace dermatologists and
radiologists. They will {\em augment} professionals, offering the
expertise and assistance".

\Org{Artificial Intelligence and Intelligence Augmentation}{
Using computers to augment human intelligence rather replace it is
both tantalizing and mundane. On the heady side, consider
cyborgs whose anatomy is part human, part artificial and can with
equal ease solve complex equations or write poetry. On the mundane
side, think of smartphones that are quickly becoming an inseparable
part of our person.
 
The idea of using computers to augment or amplify human intelligence
has a very long history. The acronyms AI (Artificial intelligence) and
IA (Intelligence Amplification or Intelligence Augmentation) have both
become popular in the early
1960's\cite{ashby1957introduction,engelbart1962augmenting}. These
days, the acronym AI is popular, while the acronym IA is not. However,
Sebastian Thrun's statement indicates that the idea of Intelligence
augmentation is still on people's mind.}

{\bf What would IA look like when applied to medicine?} that is the
question we aim to answer here.  We argue that an important ingredient
of the answer is to introduce to AI agents a level of
humility. Specifically, to design classifiers, such as DNNs, to say "I
don't know".

\section*{Labels, ground truth and testing}

\ML{Supervised Learning and ground truth}{Roughly
  speaking, machine learning (ML) can be divided into {\em
    unsupervised} learning and {\em supervised} learning. In both, the
  task of the learning algorith is transform a set of {\em examples}
  into a {\em model}. In unsupervised learning the examples are
  undifferentiated raw measurements. In {\em supervised} learning,
  which is the focus of this article, each example consists of an {\em
    input} and a {\em label}. Typically, the labels are provided by a
  human expert. These labels define the {\em ground truth} and the
  goal of the learning algorithm is to make predictions that diverge
  as little as possible from the ground truth.}


\ML{Skin cancer diagnosis using Deep Neural Networks}{One of the
  papers that provided evidence that deep neural networks might be
  able to outperform humans is the work of Esteva et
  al~\cite{esteva2017dermatologist}. They trained a Deep neural
  network to classify images of skin into three categories: benign,
  malignant and non-cancerous. The network was then tested, along with
  twenty five dermatologists on images which were labeled by a
  pathologist analysis of the biopsy. The neural network outperformed
  the human dermatologist. This is, without a doubt, an impressive
  finding. However, it is based on a retrospective analysis, in other
  words, an analysis of historical data. To predict the performance of
  the DNN when used in a dermatology practice we need to how a
  dermatologist, or any other diagnosticians, arrives at their final
  diagnostics.}

In their famous work, Esteva et al. set out to show that a classifier
trained by machine learning can performs as well as or better than
expert dermatologists.  In this application of supervised learning
each example consists of an input image of a skin patch and an output
label that is ``benign'' or ``melignant''

As they wanted to compare the system to human dermatologists they
needed a better ground truth than that provided by the dermatologists.
To that end they used the diagnosis of a biopsy as ground truth. It is
arguable that this label is more accurate than the one given by the
dermatologist, even though it depends on the human judgement of the pathologist.

However, even if we assume that pathologists labels are more reliable
than dermatology labels, the requirement that each example corresponds
to a biopsy introduces a significant bias. Under normal circumstances, patients get
biopsied only if the dermatologist thinks there is a chance of
{\color{blue}malignancy. Therefore}, the set of biopsied examples is biased towards
{\color{blue}malignancy}. It is likely that using a classifier trained in this way
on an unfiltered stream of patients will increase the number of
patients unnecessarily getting a biopsy.

\section*{Uncertainty in medicine}

Medicine is rife with risk and uncertainty. An incorrect diagnosis or
treatment can cost the patient his life and the doctor her license.

Uncertainty has many causes, we discuss some of those below.

\iffalse
and we elaborate data calibration/validation limitation, protocol limitation, and knowledge gap that are directly related to the intelligent system development. 

It is certainly expected that physicians can achieve a reliable
  decision making, probably with sufficient clinical information
  \cite{mehta2011agreement} or if only the major information is needed
  \cite{atiya2003interobserver}. However, in many cases, the quality
  of decision making might be jeopardized due to various reasons,
  among which the uncertainty in medicine is non-negligible.
\fi  

\Medicine{Patient monitoring and alarm fatigue}{ A patient monitor is
  a bedside system equipped with various bio-sensors that record,
  display and distribute different biometrics, ranging from vital
  signs such as heart rate, oxygen saturation and blood pressure, to
  high-frequency waveforms such as electrocardiogram, respiratory
  signal and arterial blood pressure. Monitors are typically used in hospitals
  and clinics to closely monitor patients at risk.
  Most patient monitors come with an alarm system that
  alerts clinicians life-threating clinical events, such as asystole,
  ventricular fibrillation, or an intubated patient being disconnected from
  the ventilator. However, such systems often suffer from a high rate
  of false alarms, which causes the medical staff to ignore the
  alarms, rendering them useless. This phenomenon, called {\em alarm fatigue} (or alarm
  overload) is a major problem in hospital care
  \cite{cvach2012monitor,brief2019top}.

\iffalse %Should probably move to uncertainty in ML
  In addition to
  solving this alarm fatigue issue by taking as much information from
  available signals as possible into account
  \cite{behar2013ecg,bai2016sequence,zong2016practical,winters2018technological,hu2019algorithm},
  there have been soaring research interests in developing intelligent
  systems. The usual goal of the intelligent system is providing
  complimentary information for physicians to make clinical decision
  \cite{Johnson2016,komorowski2018artificial}, predicting possible
  complications \cite{huddar2016predicting,meyer2018machine}, among
  others.
  \fi
  
  \yoav{What is the point of this paragraph?\\
    It is plausible that utilizing as much data as possible from the
    patient monitor could drive medical innovation and improve the
    healthcare. However, in this setup, besides the obvious data
    quality issue, like noise, the data calibration and validation
    issues are often less discussed. Due to its proprietary nature,
    researchers usually cannot calibrate or validate the recorded
    signals but assume the high data quality. As a result, it has been
    a long debate if the recorded biosignals are suitable for
    scientific research
    \cite{Ruskin2005,Feldman2006,Shelley2016,Cannesson2016}. Without a
    proper calibration or validation, it is even possible that the
    more data massively collected without proper calibration and
    validation, the more biased the developed intelligent system will
    be.}}


\yoav{PTT seems to me to be too much in the weeds for this popular
  article In \cite{lin2019unexpected}, some delicate artifacts have
  been reported regarding the pulse transit time (PTT) analysis. {\bf
    What is PTT and why is it important?} PTT is defined to be the
  phase latency between the cycles in the electrocardiogram and the
  photoplethysmogram. It has been shown that PTT contains rich
  information about the blood pressure \cite{gesche2012continuous}. It
  is thus natural to include it to an intelligent system, by learning
  how it is related to clinical outcomes, to more closely monitor the
  hemodynamics. However, it was unintentionally found that in {\em
    some} patient monitors, the PTT is contaminated by a sawtooth
  artifact that {\em might} come from some hardware manufacture
  procedure.  Since such non-physiological artifact is not universal,
  the usual statistical tools like variable selection cannot help. As
  a result, the intelligent system might be confused and lead to
  unpredictable uncertainties.  }

\yoav{I think the following should be partitioned into two blocks:
  ``Protocols and their limitations'' and ``Inter-rater agreement and
  disagreement''}
  
  \Medicine{Protocol limitation}{
  The American Academy of Sleep
    Medicine (AASM) publishes criteria for manual sleep stage
    and
    sleep apnea annotation from the gold standard sleep study instrument, the polysomnogram (PSG). This annotation is based on manual analysis
    of biosignals recorded from the PSG \cite{Iber2007,berry2012aasm}. The AASM is a protocol that has been extensively applied, with rigorous scientific support, and updated regularly according to latest evidences. 
    %
    A detail sleep profile is critical for sleep quality enhancement, or even medical condition improvement.
    %
    However, it is well known that even with the well established protocol, the inter-rater agreement rate of sleep stage annotation among experienced experts is only about 76\% over normal subjects and about 71\% over subjects with sleep apnea \cite{norman2000interobserver}. Among many reasons, the one that is directly related to the intelligent system development is how the criteria are ``described'' in the protocol. For example, it is described in the protocol that if the delta wave occupies more than 20\% of a given 30-second epoch of the electroencephalogram during sleep, that 30-second epoch is defined to be the N3 stage. 20\% of a given 30-second epoch is 6 seconds. What about if the delta wave occupies 5.99-, or 6.01-seconds? What about if the delta wave sustains for 10 seconds, but it is divided into two consecutive 30-second epochs? When sitting on the ``gray area'' that is inherited from 
  the protocol, sleep experts need to make a
  decision based on their experience or the information
  they have at hand, and this leads to medical uncertainties, and hence the inter-rater, or even intra-rater disagreement.  
  
  
    
  %For example, the inter-rater agreement rate of identifying ventricular premature contractions from a 12 leads electrocardiogram is high among well-trained cardiologists, but it will be lower if only a single lead electrocardiogram is available in the ambulatory environment.

  }

  \ML{Quantification of inter-rater agreement rate}{+Cohen's kappa,
    \yoav{Introduce Hoen kappa. Instead of mathematical definition, I
      would interpret some specific values: the value that
      corressponds to perfect agreement for positive perfect agreement
      for negative, the values that corresond to random-level
      agreement for positive and negative, etc.}}


  \Medicine{Bladder and sphincster diagnosis}{  
  Urodynamic studies provide the best bladder and sphincter functional data for urologists to decide how to treat patients at risk for renal damage \cite{abrams2003describing}.  While it has been extensively studied and applied in clinics, the main issue that plagues this field of urodynamics is the lack of precise definition of a detrusor contraction or overactive contraction \cite{abrams2003describing}.
%  
  The lack of a well defined definition is due to the lack of quantitative study from the pathophysiological perspective, so the definition is still based on ``expert opinion''. For example, usually an overactive contraction represents itself as a ``bump'' in the detrusor pressure signal. However, what is the breath and height of a bump should we call it an overactive contraction? How to distinguish a true overactive contraction from an artifact? While there have been several reference information, like abdominal pressure, that could help us identify artifacts, but it can only explain a small portion of them. 

  Unsurprisingly, this fundamental issue has led to a significant
  inter-rater disagreement
  \cite{venhola2003interobserver,dudley2018interrater}.

    \yoav{What are the cohen-kappa numbers}
  }


  Medical uncertainty as manifest low inter-rater agreement
  consequence, can be found in many clinical problems (see blocks on
  ...)For example, the low agreement might come from the
  ``extrapolation error''; that is, when we apply the developed
  protocol to the population different from the population that we
  collect the evidence for the protocol \cite{brosnan2015modest}.  In
  other situation, the variability among subjects is so big that it
  limits the development of a more quantitative protocol
  \cite{venhola2003interobserver}. In some situations, when the needed
  information is missing, it is challenging to make a differential
  diagnosis \cite{moncada2011reading}.

  A direct consequence of the low inter-rater agreement rate is that the trained intelligent system might be questionable. 
%  
It is clear that such intelligent system is questionable and might raise concerns. Recently, various regulations in this regard have been proposed \cite{price2014black,ford2016privacy}.

\hautieng{should we jump into GDPR?}
\yoav{what is GDPR?}

Now, suppose we are able to eliminate all challenges from data
calibration and validation issues, and we can provide as much
information as possible to train the intelligence system. Even under
this assumption, it is clear that the system still suffers from the
protocol limitation or knowledge gap issues. Can such system be useful
in clinics? To answer this question, we should not forget that
physicians also follow the same protocol and have knowledge
gaps. Depending on the clinical problems, and the experience of
physicians under consideration, the agreement rate varies. Usually,
intern doctors know the least, while a senior attending knows the
most. It is natural that we trust a senior expert more, but it does
not mean that we do not trust a junior intern doctor.

\iffalse %move to uncertainty in ML
The boundary of trust or not depends on the problem, and how sure the physicians know the answer. 
%
It is clearly challenging to evaluate how sure the physician is. But
when we train an intelligent system, we can easily quantify how sure
the system is about a question -- usually it is the score calculated
by the system from the input data. In a binary classification problem,
the higher or the lower the score is, the more certain the system is
about the answer to the input data. When the score is in the middle,
we could interpret that the system is {\em not sure} about the answer
to the input data, or {\em it doesn't know} (IDK).
\fi

We consider the management of uncertainty from the medical decision making process
point of view\cite{vordermark2019introduction}.
Following the ``thinking fast, thinking slow'' dualism Kahaneman and
Tversky, it is generally agreed that
two distinct mental processes are involved in choosing a diagnosis.
Recognition is a fast, typically non-verbal, mental process in which
the doctor identifies a pattern in the symptoms and instinctively
makes a diagnosyis. On the other hand, elimination is a slow
deliberative process through which the doctor methodically eliminates
diagnostic possibilities.
 To make a decision based
on elimination, slow thinking with focused attention is critical
\cite{michel2020thinking}. This process is like taking a math
examination, it takes time and effort, and it is exhaustive. In the
every end, depending on the physician experience, he/she might end up
with multiple possibilities. He/she could either guess and proceed, or
say IDK and consult a higher level experts or discuss with other
experts.
\yoav{I like the last paragraph very much, it makes a lot of
  sense. I downloaded the vordermark book. I found a lot of good
  stuff. But I did not find anything about doctors consulting each
  other, majorities, concensus etc. It would be very relevant to find
  information both about how decision are made in today's hospital,
  and how they {\em should} be made to combine the best of fast and
  slow thinking. All of this before saying anything about using ML}

\iffalse % should me moved to uncertainty in ML
An intelligent system could be extremely helpful for this
purpose. An intelligent system could help carefully and slowly
eliminate possible choices, and if it end up in a gray zone with
multiple possibilities, it says IDK. This would dramatically help
physicians daily practice.

%https://books.google.com.tw/books?id=ciK3DwAAQBAJ&pg=PA112&lpg=PA112&dq=medical+decision+making+elimination+process&source=bl&ots=Lx-GW2HLWZ&sig=ACfU3U0VNZNnBfSC6TpAZ1jvSsCkV8Rmjg&hl=en&sa=X&ved=2ahUKEwioypCxv4PqAhW1LqYKHbM0BG0Q6AEwCnoECAkQAQ#v=onepage&q=medical%20decision%20making%20elimination%20process&f=false
\fi

  \Medicine{Inter-Rater agreement}{
  A direct consequence of this low inter-rater agreement is a
  questionable trained ``artificial intelligence''. It is possible
  that we magically obtain a dataset that contains information that is
  sufficient for the decision making, while the information is too
  subtle so that it is not considered in the protocol, and we also
  magically obtain labels from a magical master that can see though
  all the information and provide the correct decision. However, by
  doing a simple math, we shall not count on such a magic and should
  come back to the protocol itself.

  \yoav{ Can you describe a particular interesting / illuminating /
    convincing case?}
}



{\bf Sources of uncertainty in medical diagnosis.}
\begin{itemize}
  \item{\bf The diagnostic process of elimination}
  \item{\bf Data Quality, Calibration, resolution} Discuss issue as placement of sensors, .
  \end{itemize}

 {\bf Hiding Uncertainty}
  \begin{itemize}
    \item {\bf Psychological reasons} Both doctor and patient prefer
      the projection of certitude.
    \item {\bf Protocols} --done
    \item {\bf diagnostic devices} Secrecy of the internal code limits
      the trustworthiness of the alarms.--done
    \item{\bf Alarm Fatigue}--done
  \end{itemize}

%{\bf Psychological reasons} Both doctor and patient prefer

How to quantify IDK? We should discuss how to quantify the confidence, or certainty, a physician has when making a decision. Clearly, experience leads to confidence. With more experience aggregated, diagnostic options that contradict the accumulated
  experience are eliminated, and hence more problems that need to be handled by the elimination process can be handled by the recognition process. However, facing our complicated human body, it is almost not possible for any single physician to aggregate all necessary experience to be confident about anything, so IDK is still an option. A practical and simple way to increase diagnostic certainty is to solicit the experience of a diverse group of doctors via discussion. If there is a clear majority for one diagnostic outcome,
      then the overall confidence in that diagnostics is high. While this voting procedure might be guarantee the optimal outcome, it eliminates the uncertainly during the whole procedure. With this certain procedure, even if the outcome is negative, it can be traced back and accumulate evidence and experience. 
%

\ML{Certainty and conditional probability}{
This certainty is very different from the the conditional probability of the disease given the diagnostic. The first is
      akin to saying: 95\% of the dermatologists would give the same
      diagnostics. The second defines the probability that, if we had
      access to ground truth, then 95\% of the patients that receive
      this diagnostics have the corresponding condition.
 }  

    
\section*{Uncertainty in Machine Learning}

One can define ``confidence'' in machine learning. The definition follows a
similar logic to the one used for human diagnosticians in the previous
section. The yardstick by which we measure confidence of predicting a
label is ``how much do alternative labels contradict previous
experience?''.
More formally, we ask how much do we need to change the training data
so that it supports an alternative label.



\ML{Uncertainty vs. accurracy}{using ROC curves}

\begin{itemize}
  \item Bootstrap samples.
  \item Samples from different hospitals.
  \item Easy and hard cases.
  \end{itemize}

  \section*{Agency and Augmentation}

  Computers are already an integral part of medicine, from
  electronical medical records to medical instrumentation to billing,
  hospitals and cliniques cannot function without computers. By some
  measures computers can already make better diagnosis that human
  doctors. The question is not {\em whether} computer diagnostics will
  become part of medical practice, the question is {\em how}.

  It is not enough to describe the desired end state. 
  In this final section we chart a {\em migration path} from the
  current limited role of computers in diagnostics to a
  more central role. For this to take place, caregivers must benefit
  from the new technology. Setting the goal to be replacing human
  doctors with machines is both unrealistic and self-defeating.

  Doctors and nurses are humans, they are not diagnostic machines. The
  personal and emotional connection between doctor and patient is
  critical for effective treatment. A good doctor combines their
  medical knowledge with a personal understanding of the patient to
  choose a treatment plan and discuss it with the patient to get their
  consent.

  It is debatable whether a computer will ever be able to
  make a meaningful emotional connection with a patient. It is quite
  clear that such capabilities will not exist in the forseable future.
  We refer to the ability to connect and to act in a self concious
  way {\em agency} and separate it from {\em intelligence}. We suggest
  that computers can augment humans in intelligence tasks and leave
  agency to humans.

  \subsection*{Easy and hard diagnoses}

  As described above, diagnostics is a process of elimination. It
  starts with a set of possible diagnoses which are gradually
  eliminated as evidence is  gathered. As diagnoses are
  eliminated, the benefit and risk of different treatment plans is evaluated.
  Deciding on treatment and continually monitoring it is where the
  doctor's agency is most important.

  Our suggestion is that machine learning helps the doctor eliminate
  diagnoses and evaluate treatment options, while leaving the the
  decisions to the doctor.

  Diagnosis vary in their difficulty. Consider a sequence of
  patients visiting a clinic. Suppose the clinic has four doctors, two
  trainees, and six nurses. Each patient first gets seen by a nurse,
  then by a doctor, and possibly by a trainee. Some of patients have
  a simple diagnosis, one that all twelve members of the clinic will
  state with confidence. Other patients have more complex diagnosis
  that requires the attention of a doctor. Finally, some diagnosis are
  so complex that the doctor needs to consult other doctors and
  possibly ask for additional tests. In other words, the clinic acts
  as an ensemble of classifiers. Easy cases result in a unanimous
  diagnosis, harder ones results in a clear majority, and the very
  hardest results in disagreement which requires consultation and
  additional tests.

  The machine learning ensemble of classifiers follows a similar
  logic. 

\begin{itemize}
\item{\bf Computer aided diagnostics}
  Especially with very large data: ecg for 14 says.... \\
  ~\\

Pathology.

\item {\bf Dissemination of expertise}
Computers, trained by experts, can help novices.  Serves a function
similar to score-cards.

Teaching young diagnostics
\item { \bf Confidence, Trust and adoption of technology}
\end{itemize}

\section*{Summary}

%\bibliographystyle{alpha} 
\bibliography{medbib}

\end{document}