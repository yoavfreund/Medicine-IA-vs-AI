\documentclass[11pt]{pnas-new}
% \documentclass[10pt]{article}
\templatetype{pnasresearcharticle} % Choose template 
% {pnasresearcharticle} = Template for a two-column research article
% {pnasmathematics} %= Template for a one-column mathematics article
% {pnasinvited} %= Template for a PNAS invited submission

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{xcolor,ulem}
\usepackage{mdframed}
\usepackage{wrapfig}
\usepackage{multicol}
\setlength{\columnsep}{1cm}
\usepackage{graphicx}
\usepackage{adjustbox}
\usepackage{lipsum}
\newlength{\strutheight}


\author[1]{Yoav Freund}
\author[2]{Hau-Tieng Wu}
\affil[1]{UCSD, Computer Science, San Diego, 92093, United States}
\affil[2]{Duke, department, city, postcode, country}

\title{You should prefer a digital Doctor that can say\\ "I don't know"}

\input{macros}

\begin{abstract}

  The meteoric rise of AI in general and Deep Learning in particular
  is generating great excitement throughout academia and commerce, and
  in particular in medicine\cite{topol2019deep,
    wachter2015digital}. With some some high-profile claims~\cite{}
  that AI will soon replace humans in many medical specialties.

  In this position paper we present an alternative view. We contrast
  {\em Artificial Intelligence} with {\em Intelligence Augmentation}
  and argue that the second is more likely to benefit the patient than
  the first. We provide evidence to this argument and present a vision
  in which easier decisions are delegated to computers, while the more
  difficult ones are handled by humans.

\end{abstract}

\begin{document}
\settoheight{\strutheight}{\strut}

 
\maketitle

%\thispagestyle{firststyle}

The meteoric rise of AI and Deep learning raises the possibility that
doctors will be replaced computers~\cite{Mukherjee2017}. Geoff Hinton,
a famous deep learning researcher said in 2017: ``It's just completely
obvious that in ten years deep learning is going to do better than
Radiologists ... They should stop training radiologists now''.

The predictions of Sebastian
Thrun~\cite{Mukherjee2017,esteva2017dermatologist}, another leader in
machine learning, are less disruptive: ``... deep learning devices
will not replace dermatologists and radiologists. They will {\em
  augment} professionals, offering the expertise and assistance''. In
this article we argue for Thrun's prediction and explain why
augmentation, rather than replacement, is the approach more likely to
prevail.

\input{AIIABox} The question of whether dermatologists will be
replaced by computers or be empowered by computers is but a recent
incarnation of a debate between AI (Artificial Intelligence) and IA
(Intelligence amplification) which has a long history (see inset). To
distinguish between AI and IA we use the terms ``AI agent'' vs. ``IA
sidekick''. This terminology contrasts {\em agents}, which are endowed
with {\em agency} and can take {\em actions} that effect the patient's
health, with {\em sidekicks} which can provide advice and suggestions,
but who are not allowed to take action.

Replacing dermatologists with AI agents can bring cost savings,
but is likely to lead to inferior care. One of the reasons is that it
is hard for AI to make a human connection with the patient and thereby
take into consideration personal, social, financial and mental factors.

On the other hand, IA powered sidekicks IA can help the medical staff
detect and diagnose medical problems quickly, efficiently,
accurately. This can lead to cost savings, especially for homebound
patients suffering from chronic diseases.

Central to our approach is a quantification of {\em prediction
  confidence}. Such quantification is needed to avoid premature
diagnostic conclusions, and to decide which additional tests or
consultations might be needed. Consider a doctor that is asked asked
to diagnose a patient with complex or conflicting symptoms. A careful
doctor will admit their uncertainty and perform additional tests or
ask a specialist. A less careful, overly self confident doctor is
likely give an incorrect diagnosis and choose an ineffective or even damaging
treatment plan.

An AI agent, trained to be better than the human doctor, might end up
behaving like an overly confident doctor. An IA sidekick, aware of
it's own limitations, will give advice only when the evidence is
strong and otherwise say ``I don't know''.

In the following sections we explore these ideas in more detail. We
start with a critique of one of the papers that claims that AI agents
can outpeform human diagnosticians.

\section{Supervised Learning and the Ground Truth}
\label{sec:ground-truth}

Deep learning is a special case of {\em supervised learning} (see
inset), sometimes called {\em input-output}
learning~\cite{ng2016artificial,topol2019deep}.
\input{Supervised}
The data for supervised learning consists of a large collection
(input,output) pairs. For medical diagnosis, the inputs is medical
information for the patient (Heart rate, blood tests, X-ray images
etc.) and the output is the diagnosis. This output is considered the
``ground-truth'' and is assumed to represent the undisputed truth.

Here lies the the first difficulty with applying supervised learning
to medical diagnosis. In most real-world scenarios the diagnosis
does is not an objectively measurable fact, rather, it
represents the conclusion drawn by a fallible human diagnostician. We  will
return to this issue in the next section.

The other important assumption made in supervised learning is that the
generated classifier is tested using the same distribution of examples
as that of the training set.

We now consider a study in deep neural networks which claims to show
that DNNs can perform diagnostics as well as, or better, than human diagnosticians. 
\input{SkinCancer}
In a highly cited paper in the journal
Science~\cite{esteva2017dermatologist} provides evidence supporting
the claim that computers can diagnose skin cancer as well or better than board
certified dermatologists.

A fundamental problem with the experiment is in the way the data was
collected. The data used in the experiment was {\em retrospective},
i.e. it was collected from the records of past patients for which both
a skin image and a biopsy were available. Normally, patients get
biopsied only if the dermatologist thinks there is a significant
chance of {\bf malignancy}. As a result, a retrospective study that is
based on patients for whom a biopsy was taken is likely to
over-represent malignant patients and therefor be biased. If an image-based classifier
is trained on the biased data, its performance on unbiased test data
is likely to be worse. Specifically, when the classifier is applied to skin
images of undiagnosed patients it is likely to over-diagnose them as
malignant. The practical implication would be that more patients than
necessary will be biopsied.
%\input{Arrhythmia}

As we elaborate on in the next section, in medical diagnostics the
ground truth is usually not available, all that we have to go on are
the opinions of human diagnosticians.

\section{Uncertainty in medicine}

For the most part, it is hard to associate ground truth with medical
diagnostics. This is evident studies of {\em inter-rater agreement} (see
inset). In studies of this kind multiple doctors produce diagnostics
based identical medical information without communicating with each other. 
\input{InterRaterAgreement}

In addition, diagnosis is not an input-output mapping. Rather, it
is an iterative process which reduces uncertainty over time. To
illustrate this, consider the diagnostics of a patient that is treated
in an out-patient clinique..  When a patient arrives at a clinique for
the first time, all diagnostics are possible. After a physical exam
and an interview with a doctor, , many possibilities are
eliminated. In {\em simple} cases, this is enough for the doctor to
confidently chooabelse a treatment. In more complex cases, the doctor
might ask for multiple tests and visits, refer the patient to a
specialist, consult colleagues, journals and books etc. To choose a
treatment plan, the set of possible diagnostics has to be reduced
however, it does not have to be reduced to a {\em single} diagnostics,
as multiple diagnostics might share a treatment plan.

In order to apply a supervised learning method, such as  DNN, to the
diagnostic problem, we need to define a ground-truth label for each
patient. But that is easier said than done. As the final output of the
diagnostic process is a treatement plan, we would like to know what is
the best treatment plan. Unfortunately, we can only use a single
treatment plan to treat the patient, so the most that we might be able
to infer is whether the chosen treatment was effective.  Even if the
patient improved, the cause might have been unrelated to the
treatment. It might be due to a change in diet or reduction in stress.
Moreover, in most cases, there are few or none followup visits and as
a result there is no data as to whether the patient has a lasting
improvement in health.

We suggest a different goal for automatic diagnosis.
Rather than predicting the {\em ``correct''}
diagnosis we define the goal of the computer to be predicting the {\em
  distribution} of diagnosis across doctors. In addition, we allow
doctors to be uncertain of their own diagnosis.
The distribution of doctors predictions represents their confidence as
a group. In other words, by predicting that all doctors will agree on
the diagnosis, we assign high confidence to that diagnosis. 
If, on the other hand, we
predict that doctors will give one (or both) of two diagnoses A and B, then
our prediction is akin to saying ``we are confident that the prediction
is either A or B, to know which one we will need additional
tests''. This accurately represents our current state in the
diagnostic process and is more useful than deciding on one diagnostic
with insufficient evidence.

It is certainly expected that physicians can achieve a reliable
decision making, probably with sufficient clinical information
\cite{mehta2011agreement} or if only the major information is needed
\cite{atiya2003interobserver}. However, in many cases, the quality of
decision making might be jeopardized due to various reasons, among
which the uncertainty in medicine is non-negligible.
\yoav{I find the previous paragraph unclear and confusing, We should
  talk about it}

%Medical uncertainty as manifest by low inter-rater agreement consequence,
%can be found in many clinical problems
There are many causes for uncertainty in medical diagnosis. We briefly
describe four categories of problems: {\em signal quality}, {\em knowledge gap}, the limitations of {\em
  diagnostic protocols} and {\em alarm fatigue}.


By {\bf Signal Quality} we refer to the quality of the raw data
collected for medical diagnosis. Some diagnostic measures, such
as heart rate, blood pressure and temperature can be measured reliably
and accurately. On the other hand, modern
devices such as EKG, EEG, camera images, X-ray, ultra-sound and EMR
produce vast and highly variable data. The quality of this data
depends on may factors among them, the quality of the instruments, the
consistency of the human operator, the build of the patient etc.
\input{SignalQuality}

Knowledge gap bla bla
\input{KnowledgeGap}

\newpage

Another factor that impacts the accuracy and consistency of the
diagnosis is the uniformity of criteria across doctors and institutions
\input{ProtocolLimitations}

bla bla
\input{AlarmFatigue}


% {\color{blue}Besides the above-mentioned reasons, there are more. For
%   example,} in some situations, when the needed information is
% missing, it is challenging to make a differential diagnosis
% \cite{moncada2011reading}.  {\color{blue}Despite the variety of
%   reasons, the key message here is that medical uncertainty is a
%   non-negligible fact in medicine.}

%   A direct consequence of the low inter-rater agreement rate is that the trained intelligent system might be questionable.
   
It is clear that such intelligent system is questionable and might
raise concerns. Recently, various regulations in this regard have been
proposed \cite{price2014black,ford2016privacy}.


Now, suppose we are able to eliminate all challenges from data
calibration and validation issues, and we can provide as much
information as possible to train the intelligence system. Even under
this assumption, it is clear that the system still suffers from the
protocol limitation or knowledge gap issues. Can such system be useful
in clinics? To answer this question, we should not forget that
physicians also follow the same protocol and have knowledge
gaps. Depending on the clinical problems, and the experience of
physicians under consideration, the agreement rate varies. Usually,
intern doctors know the least, while a senior attending knows the
most. It is natural that we trust a senior expert more, but it does
not mean that we do not trust a junior intern doctor.

\subsubsection*{Managing uncertainty in medicine}
Medical diagnosis is often uncertain or inconclusive. On the other
hand, a doctor responsible for a patient's health has to make
decisions in spite of this uncertainty. If the uncertainty presents a
sufficiently small risk, the doctor can choose a treatment. Otherwise
the doctor might consult other doctors, a medical journal or a book. 

To better understand the process and the possible place of AI in it,
we turn to the Kahaneman's~\cite{kahneman2011thinking} ``Thinking Fast Thinking Slow'' and
to Vordermark book on medical decision
making~\cite{vordermark2019introduction}.

Medical diagnosis can be divided into two main types: {\em
  recognition} and {\em elimination}. Recognition is a fast mental
process that is partially unconscious where the one correct diagnosis presents itself in the doctors mind.  Sometimes the doctor is not able to explain their recognition in words, which hinders discussion and documentation.  As recognition 
typically points to a single diagnosis, there is a danger that the
recognized diagnosis will hide other possible diagnoses.
Elimination, on the other hand, is a slow deliberate process  which starts with all possible diagnoses and gradually eliminates
unlikely ones based on patient history, examination and test
results. As Elimination is deliberative, it is easier to discuss and
document it.

In both recognition and elimination, past experience plays an important role. This experience is based on medical practice as well as knowledge learned from lectures or books. 

IA can aid the doctor both in Recognition and in Elimination. On the Recognition side, an IA can sift through massive data and point the diagnostician to suspicious areas.

On the Elimination side, an IA system could help carefully and systematically
eliminate diagnoses. This can help the doctor stay aware of possibilities that are not obvious, for differential diagnosis.


\iffalse
To make a decision based
on elimination, slow thinking with focused attention is critical
\cite{michel2020thinking}. 

An intelligent system could be extremely helpful for this
purpose. An intelligent system could help carefully and slowly
eliminate possible choices, and if it end up in a gray zone with
multiple possibilities, it says IDK. This would dramatically help
physicians daily practice.


{\bf Sources of uncertainty in medical diagnosis.}
\begin{itemize}
  \item{\bf The diagnostic process of elimination}
  \item{\bf Data Quality, Calibration, resolution} Discuss issue as placement of sensors, .
  \end{itemize}

 {\bf Hiding Uncertainty}
  \begin{itemize}
    \item {\bf Psychological reasons} Both doctor and patient prefer
      the projection of certitude.
    \item {\bf Protocols} --done
    \item {\bf diagnostic devices} Secrecy of the internal code limits
      the trustworthiness of the alarms.--done
    \item{\bf Alarm Fatigue}--done
  \end{itemize}
\fi
%{\bf Psychological reasons} Both doctor and patient prefer

How to quantify IDK? We should discuss how to quantify the confidence, or certainty, a physician has when making a decision. 
\ML{Certainty and conditional probability}{
This certainty is very different from the the conditional probability of the disease given the diagnostic. The first is
      akin to saying: 95\% of the dermatologists would give the same
      diagnostics. The second defines the probability that, if we had
      access to ground truth, then 95\% of the patients that receive
      this diagnostics have the corresponding condition.
}  
Clearly, experience leads to confidence. With more experience aggregated, diagnostic options that contradict the accumulated
  experience are eliminated, and hence more problems that need to be handled by the elimination process can be handled by the recognition process. However, facing our complicated human body, it is almost not possible for any single physician to aggregate all necessary experience to be confident about anything, so IDK is still an option. A practical and simple way to increase diagnostic certainty is to solicit the experience of a diverse group of doctors via discussion. If there is a clear majority for one diagnostic outcome,
      then the overall confidence in that diagnostics is high. While this voting procedure might guarantee the optimal outcome, it eliminates the uncertainty during the whole procedure. With this certain procedure, even if the outcome is negative, it can be traced back and accumulate evidence and experience. 

\section{Uncertainty in Machine Learning}

One can define ``confidence'' in machine learning. The definition follows a
similar logic to the one used for human diagnosticians in the previous
section. The yardstick by which we measure confidence of predicting a
label is ``how much do alternative labels contradict previous
experience?''.
More formally, we ask how much do we need to change the training data
so that it supports an alternative label.
%\ML{Uncertainty vs. accurracy}{using ROC curves}

\begin{itemize}
  \item Bootstrap samples.
  \item Samples from different hospitals.
  \item Easy and hard cases.
  \end{itemize}

  \section{Human decisions and Intelligence augmentation}

  Computer {\color{blue}has been} an integral part of medical practice {\color{blue}for decades}. From
  {\color{blue}electronic} medical records (EMR) to medical instrumentation to billing,
  hospitals and cliniques cannot function without computers. By some
  measures computers can already make better diagnosis than human
  doctors. The question is not {\em whether} computer diagnostics will
  become part of medical practice, the question is {\em how}.

  Some claim that human doctors and nurses are heading to extinction,
  following the fate of manufacturing jobs and bank cashiers.  Our prediction is
  that computers will change the nature of medical work, but that it
  will increase, rather than decrease, the number of healthcare
  workers, especially in the care of chronic disease and aging{\color{blue}, and exploring the nature of our complicated human body}. 

  We believe computers {\em can} perform accurate diagnosis for cases where
  different doctors are likely to agree. In other cases {\color{blue}that are in the}
  diagnostic gray area, the computer will output ``I don't know'' and
  transfer the responsibility to the doctor. In most cases, the doctor
  cannot say ``I don't know'' because she is responsible for the
  patients health. On the other hand, resolving the diagnostic
  question is not her only choice. She can consult another doctor or
  the literature, ask for additional tests, or decide on a treatment
  based on available information. Deciding between these options requires much
  more than diagnostic information. It involves understanding the
  patient's emotional, mental and financial state, the patient's
  support system, the strengths and weaknesses of the hospital in
  which this is taking place etc. {\color{blue}Such exploration and results will be fed back to the system to reduce the gray area, which is similar to training an intern doctor in the hospital.}

  Over time, computers will be able to take into consideration more
  and more of this complex information. However, for the foreseeable
  future, it is unlikely that computers will be given the
  responsibility to make medical {\em decisions}. Computers
  will take on much of the diagnostics and alarm tasks, improving the
  accuracy and timeliness of the doctors actions. Computers will
  output IDK in gray areas and will leave the decision making to the
  human doctor. Giving the computer the authority to make decisions
  currently done by human doctors will {\color{blue}not only} deprive the patient the human
  attention of the doctor{\color{blue}, but also put patients in risk}.

  Some of the digitization of the medicine has come between patients
  and doctors. {\color{blue}A common impression from the learning perspective is that physicians need to record more activities and hence reduce the amount of time on interacting with patients. However, we} %\sout{The need to record all activities into the EMR system requires doctors to spend more time at the keyboard, reducing the amount of time of physical examination an discussion}. \hautieng{I guess I know what you want to say, but to be safe, I'll do the edit here after we chat.} 
  believe that {\color{blue}a properly designed } IA {\color{blue}that knows IDK} can
  move medicine in the opposite direction, letting the computer make
  the common noncontroversial diagnostics and giving the patient more
  time to interact with the patient.

\begin{figure}[h]
\begin{center}
\includegraphics[trim=0 100 0 200,clip,width=7in]{figures/RedYellowGreen2.pdf}
\caption{An illustration of how an alarm system works as a radar system. The red and green pentagons indicate the danger and safe region of five indices. A set of indices inside the green pentagon is safe (shown as a green light). If any index is outside the red pentagon, the patient is surely in danger (shown as a red light). However, if any index is outside the green pentagon but inside the red pentagon, the patient is in a ``gray zone'', or marginal situation, the system might not be able to decide the situation, and will report IDK (shown as a yellow light).\label{Figure IDK light}}
\end{center}
\end{figure}

  For IA technology to be widely adopted, the nurses and doctors that
  use them should experience an improvement in their practice {\color{blue}with the IA system. One example of such system is}
  that the display of the diagnostics computer uses a three color code
  to identify {\color{blue}the pre-defined status. In this system,} green indicates a confident
  negative diagnostic, red corresponds to a confident positive
  diagnosis, and yellow corresponds to IDK, meaning that the
  computer cannot confirm or reject the diagnostic outcome. {\color{blue}See Figure \ref{Figure IDK light} for an illustration of such a system with a radar display. The thresholds that define these three ranges depend on our knowledge, and the data uncertainty and protocol issues should be taken into account. With the IA system with IDK, healthcare providers could focus their time on patients overall situation, communication for life plan, or other interactions, and intervene the medical diagnostics when the IA system says IDK.}

%  The thresholds which define the three ranges .... \hautieng{discuss.}


  
  We finish this section with a few application areas which seem ready
  for applications of IA.
  
\begin{itemize}
\item{\bf Computer aided diagnostics for large-scale data}\\
  Medical imaging devices such at digital X-ray, CT, EMR and scanning
  microscope generate many gigabytes of data for each
  patient. Radiologists and pathologists spend their days analyzing
  these images to diagnose the patient. The large size and high
  resolution of the images on the one hand, and the time limitation on
  the analyst on the other imply that the analyst has to quickly
  narrow down the suspicious region, increase the chance of missing
  dangerous abnormalities.

  IA can help the pathologist by suggesting locations in the high
  resolution image that might contain cancer nodules~\cite{}.

  directing her attention to the
  parts of the image that are 

\item{\bf Adaptive Patient monitors}

{\color{blue}Alarm fatigue is a well known issue medical providers encounter when working with patient monitors. It is frequently named as a threat to patient safety \cite{sendelbach2013alarm,ruskin2015alarm}, and a lot of research has been carried out toward this problem \cite{cvach2012monitor,paine2016systematic,bai2016sequence,hu2019algorithm}. By further accumulating knowledge, reducing data uncertainty, and improving protocol, it is expected that the gray zone a well developed IA system has is small, and the alarm fatigue issue is alleviated since it only makes an alarm when it runs into IDK. There are many other aspects such an IA system equipped with IDK could help. Since the system knows IDK, it knows what is affirmative. When a medical decision made by a physician falls in the affirmative area, the IA system could help doubly confirm if the decision has any risk not considered by the physician. Such alarm, when sufficiently accurate, could help improve patient risk and healthcare quality. Eventually, this IA system could be evolved into a second opinion provider to healthcare providers. 
}


  
\item {\bf Dissemination of expertise}

Computers, trained by experts, can help novices. {\color{blue}A well-trained IA system equipped with IDK can provide confirmed answers to inexperienced physicians, and} serve a function
similar to score-cards{\color{blue}. Moreover, it can be applied to areas with scarce health resource. The system can provide local healthcare providers knowledge they do not know, and be connected back to physicians with richer medical knowledge when it runs into IDK.
On the high level, eventually, we can view an IA system with IDK as a medical specialist full of knowledge and do not make mistake when it knows the answer. When it encounters IDK, it will not hide it. The feedback from experienced physicians, or newly developed knowledge, could be input to decrease the gray areas, and reduce the chance of encountering IDK. Such system in the beginning behaves like an intern doctor, and teaching it is like}
teaching young diagnostics. {\color{blue}Due to the brain capacity and physical limitation, it is impossible for a single physician to know everything in every field, and it is possible that even a very experienced physician could make a mistake. Such a well trained IA system can eventually serve as a reliable second opinion provider to experienced physicians.}
\end{itemize}

\section{Summary}

%\bibliographystyle{alpha} 
\bibliography{medbib}

\end{document}