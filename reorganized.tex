\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{color}
\title{When the digital Doctor should admit\\ "I don't know"}

\author{Yoav Freund \and Hau-Tieng Wu}
%\affil[1]{UCSD, department, city, postcode, country}
%\affil[2]{Duke, department, city, postcode, country}

%\keywords{Keyword1, Keyword2, Keyword3}

\newcommand{\comment}[3]{{\color{#1} {\bf #2 :} #3}}
%\newcommand{\comment}[3]{}  % suppress comments
\newcommand{\hautieng}[1]{\comment{blue}{hautieng}{#1}}
\newcommand{\yoav}[1]{\comment{red}{Yoav}{#1}}


\begin{document}

\maketitle

\begin{abstract}

  The meteoric rise of AI in general and Deep Learning in particular
  is generating great excitement throughout academia and commerce, and
  in particular in medicine\cite{topol2019deep,
    wachter2015digital}. With some some high-profile claims~\cite{}
  that AI will soon replace humans in many medical specialties.

  In this position paper we present an alternative view. We contrast
  {\em Artificial Intelligence} with {\em Intelligence Augmentation}
  and argue that the second is more likely to benefit the patient than
  the first. We provide evidence to this argument and present a vision
  in which easier decisions are delegated to computers, while the more
  difficult ones are handled by humans.

\end{abstract}

%\thispagestyle{empty}

\section*{Introduction}

Digital technology is causing a sea-change in all parts of the medical
profession. In particular the meteoric rise of AI in general and deep
learning in particular raises the possibility that doctors will be
replaced computers~\cite{Mukherjee2017}. The father of deep learning,
Geoff Hinton, said in 2017: "It's just completely obvious that that in
ten years deep learning is going to do better than Radiologists
... They should stop training radiologists now".

Other deep learning researchers provide a more nuanced
perspective. Sebastian
Thrun~\cite{Mukherjee2017,esteva2017dermatologist} argues that
"... deep learning devices will not replace dermatologists and
radiologists. They will {\em augment} professionals, offering the
expertise and assistance".

Using computers to augment human intelligence rather replace it, is,
at the same time, both heady and boring. On the heady side, consider
cyborgs whose anatomy is part human, part artificial and can with
equal ease solve complex equations or write poetry. On the mundane
side, think of smartphones that are quickly becoming an inseparable
part of our person.
 
The idea of using computers to augment or amplify human intelligence
has a very long history. The acronyms AI (Artificial intelligence) and
IA (Intelligence Amplification or Intelligence Augmentation) have both
become popular in the early
1960's\cite{ashby1957introduction,engelbart1962augmenting}. These
days, the acronym AI is popular, while the acronym IA is not. However,
Sebastian Thrun's statement indicates that the idea of Intelligence
augmentation is still on people's mind. We suggest bringing it back.

{\bf What would IA look like when applied to medicine?} We argue that
one important ingredient is to endow AI agents with a degree of
humility. Specifically, to allow classifiers, such as DNNs, to say "I
don't know".


\section*{Labels, ground truth and testing}
\yoav{I think this and other technical sections should appear in a
  separate text box.}

Roughly speaking, machine learning (ML) can be divided into {\em unsupervised}
learning and {\em supervised} learning. In both, the task of
the learning algorith is transform a set of {\em examples} into a {\em model}. In
unsupervised learning the examples are undifferentiated raw
measurements. In {\em supervised} learning, which is our main concern
here, each example consists of an {\em input} and a {\em label}. In
the work of Esteva et al~\cite{esteva2017dermatologist} on classification of skin
cancer the input is an image of a skin patch and the label is
``benign'' or ``melignant''.

Typically, the labels are provided by a human expert. These labels
define the {\em ground truth} and the goal of the learning algorithm is
to make predictions that diverge as little as possible from the ground
truth. As discussed in the next section, ground truth is usually not
available in regular medical practice. In this section we point out a
problem with the ground truth use in ~\cite{esteva2017dermatologist}.

Esteva et al~\cite{esteva2017dermatologist} set out to show that ML
can performs as well as or better than expert dermatologists. This
meant that they needed to use for ground-truth a label that is more
objective than a dermatologist. To that end they used the diagnosis of
a biopsy as ground truth. There is no argument that this is a better
ground truth than the opinion of a dermatologist.

The problem with this design is that under normal circumstances, patients get
biopsied only if the dermatologist thinks there is a chance of
melignancy. Therefor, the set of biopsied examples is biased towards
melignancy. It is likely that using a classifier trained in this way
on an unfiltered stream of patients will increase the number of
patients unnecessarily getting a biopsy.

\section*{Uncertainty in medicine}

{\bf Sources of uncertainty in medical diagnosis.}
\begin{itemize}
  \item{\bf The diagnostic process of elimination}
  \item{\bf Data Quality, Calibration, resolution} Discuss issue as
    placement of sensors, lighting when analyzing skin lesions. Sensing back for re-testing.
  \end{itemize}

 {\bf Hiding Uncertainty}
  \begin{itemize}
    \item {\bf Psychological reasons} Both doctor and patient prefer
      the projection of certitude.
    \item {\bf Protocols}
    \item {\bf diagnostic devices} Secrecy of the internal code limits
      the trustworthiness of the alarms.
    \item{\bf Alarm Fatigue}
  \end{itemize}

  {\bf Quantifying Confidence} With experience comes confidence. In
  other words, diagnostic options that contradict the accumulated
  experience are eliminated.
  
  {\bf confidence through aggregation}
  \begin{itemize}
    \item A good way to increase diagnostic certainty is to solicit
      the experience of a diverse group of doctors.
    \item If there is a clear majority for one diagnostic outcome,
      then the overall confidence in the diagnostics is high.
    \item This certainty is very different from the the conditional.
      probability of the disease given the diagnostic. The first is
      akin to saying: 95\% of the dermatologists would give the same
      diagnostics. The second defines the probability that, if we had
      access to ground truth, then 95\% of the patients that recieve
      this diagnostics have the corresponding condition.
    \end{itemize}
    
\section*{Uncertainty in Machine Learning}

One can define ``confidence'' in machine learning. The definition follows a
similar logic to the one used for human diagnosticians in the previous
section. The yardstick by which we measure confidence of predicting a
label is ``how much do alternative labels contradict previous
experience?''.
More formally, we ask how much do we need to change the training data
so that it supports an alternative label.

\yoav{In box: uncertainty versus accuracy using ROC curves}

\begin{itemize}
  \item Bootstrap samples.
  \item Samples from different hospitals.
  \item Easy and hard cases.
  \end{itemize}

\section*{Agency and Augmentation}
\yoav{Doctors need to adapt. Why would doctors prefer to adapt than to
  resist? What is the migration path for augmentation in medicine?}
\begin{itemize}
\item{\bf Computer aided diagnostics}
  Especially with very large data: ecg for 14 says.... \\
  ~\\

Pathology.

\item {\bf Dissemination of expertise}
Computers, trained by experts, can help novices.  Serves a function
similar to score-cards.

Teaching young diagnostics
\item { \bf Confidence, Trust and adoption of technology}
\end{itemize}

\section*{Summary}

\bibliographystyle{alpha} 

\bibliography{medbib}

\end{document}