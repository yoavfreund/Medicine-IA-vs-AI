\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{color}
\title{When the digital Doctor needs to admit\\ "I don't know"}

\author{Yoav Freund \and Hau-Tieng Wu}
%\affil[1]{UCSD, department, city, postcode, country}
%\affil[2]{Duke, department, city, postcode, country}

%\keywords{Keyword1, Keyword2, Keyword3}

\newcommand{\comment}[3]{{\color{#1} {\bf #2 :} #3}}
%\newcommand{\comment}[3]{}  % suppress comments
\newcommand{\hautieng}[1]{\comment{blue}{hautieng}{#1}}
\newcommand{\yoav}[1]{\comment{red}{Yoav}{#1}}


\begin{document}

\maketitle

\begin{abstract}

  The meteoric rise of AI in general and Deep Learning in particular
  is generating great excitement throughout academia and commerce, and
  in particular in medicine\cite{topol2019deep,
    wachter2015digital}. With some some high-profile claims~\cite{}
  that AI will soon replace humans in many medical specialties.

  In this position paper we present an alternative view. We contrast
  {\em Artificial Intelligence} with {\em Intelligence Augmentation}
  and argue that the second is more likely to benefit the patient than
  the first. We provide evidence to this argument and present a vision
  in which easier decisions are delegated to computers, while the more
  difficult ones are handled by humans.

\end{abstract}

%\thispagestyle{empty}

\section*{Introduction}

Digital technology is causing a sea-change in all parts of the medical
profession. In particular the meteoric rise of AI in general and deep
learning in particular raises the possibility that doctors will be
replaced computers~\cite{Mukherjee2017}. The father of deep learning,
Geoff Hinton, said in 2017: "It's just completely obvious that that in
ten years deep learning is going to do better than Radiologists
... They should stop training radiologists now".

Other deep learning researchers provide a more nuanced
perspective. Sebastian
Thrun~\cite{Mukherjee2017,esteva2017dermatologist} argues that
"... deep learning devices will not replace dermatologists and
radiologists. They will {\em augment} professionals, offering the
expertise and assistance".

Using computers to augment human intelligence rather replace it, is,
at the same time, both heady and boring. On the heady side, consider
cyborgs whose anatomy is part human, part artificial and can with
equal ease solve complex equations or write poetry. On the mundane
side, think of smartphones that are quickly becoming an inseparable
part of our person.
 
The idea of using computers to augment or amplify human intelligence
has a very long history. The acronyms AI (Artificial intelligence) and
IA (Intelligence Amplification or Intelligence Augmentation) have both
become popular in the early
1960's\cite{ashby1957introduction,engelbart1962augmenting}. These
days, the acronym AI is popular, while the acronym IA is not. However,
Sebastian Thrun's statement indicates that the idea of Intelligence
augmentation is still on people's mind. We suggest bringing it back.

{\bf What would IA look like when applied to medicine?} We argue that
one important ingredient is to endow AI agents with a degree of
humility. Specifically, to allow classifiers, such as DNNs, to say "I
don't know".


\section*{Labels, ground truth and testing}
\yoav{I think this and other technical sections should appear in a
  separate text box.}

Roughly speaking, machine learning (ML) can be divided into {\em unsupervised}
learning and {\em supervised} learning. In both, the task of
the learning algorith is transform a set of {\em examples} into a {\em model}. In
unsupervised learning the examples are undifferentiated raw
measurements. In {\em supervised} learning, which is our main concern
here, each example consists of an {\em input} and a {\em label}. In
the work of Esteva et al~\cite{esteva2017dermatologist} on classification of skin
cancer the input is an image of a skin patch and the label is
``benign'' or ``melignant''.

Typically, the labels are provided by a human expert. These labels
define the {\em ground truth} and the goal of the learning algorithm is
to make predictions that diverge as little as possible from the ground
truth. As discussed in the next section, ground truth is usually not
available in regular medical practice. In this section we point out a
problem with the ground truth use in ~\cite{esteva2017dermatologist}.

Esteva et al~\cite{esteva2017dermatologist} set out to show that ML
can performs as well as or better than expert dermatologists. This
meant that they needed to use for ground-truth a label that is more
objective than a dermatologist. To that end they used the diagnosis of
a biopsy as ground truth. There is no argument that this is a better
ground truth than the opinion of a dermatologist.

The problem with this design is that under normal circumstances, patients get
biopsied only if the dermatologist thinks there is a chance of
melignancy. Therefor, the set of biopsied examples is biased towards
melignancy. It is likely that using a classifier trained in this way
on an unfiltered stream of patients will increase the number of
patients unnecessarily getting a biopsy.

\section*{Uncertainty in medicine}

\yoav{The different sources of uncertainty in medical diagnosis.}

\begin{itemize}
  \item{\bf The diagnostic process of elimination}
  \item{\bf Data Quality, Calibration, resolution} Discuss issue as
    placement of sensors, lighting when analyzing skin lesions. Sensing back for re-testing.
  \end{itemize}

  Hiding Uncertainty
  \begin{itemize}
    \item {\bf Psychological reasons} Both doctor and patient prefer
      the projection of certitude.
    \item {\bf Protocols}
    \item {\bf diagnostic devices} Secrecy of the internal code limits
      the trustworthiness of the alarms.
    \item{\bf Alarm Fatigue}
  \end{itemize}
  

\section*{Uncertainty in Machine Learning}

\yoav{In box: uncertainty versus accuracy using ROC curves}
  
Committees, Agreement, Easy and Hard cases
Our approach for distinguishing easy and hard cases.

\paragraph*{The semantics of ``I don't know''}
Based on conforming / contradictory experience. Not on conditional
probability.


\section*{Agency and Augmentation}
\yoav{Doctors need to adapt. Why would doctors prefer to adapt than to
  resist? What is the migration path for augmentation in medicine?}
\begin{itemize}
\item{\bf Computer aided diagnostics}
  Especially with very large data: ecg for 14 says.... \\
  ~\\

Pathology.

\item {\bf Dissemination of expertise}
Computers, trained by experts, can help novices.  Serves a function
similar to score-cards.

Teaching young diagnostics
\item { \bf Confidence, Trust and adoption of technology}
\end{itemize}

\section*{Summary}

\bibliographystyle{alpha} 

\bibliography{medbib}

\end{document}